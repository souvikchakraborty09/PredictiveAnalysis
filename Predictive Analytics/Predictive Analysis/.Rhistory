x<-1:5
x
class(x)
emp.data<-data.frame(
emp_id=c(1:5),
emp_name=c("Souvik","Kriti","Ganesh","Pranav","Abhinav"),
starting_date=as.Date(c("2012-03-01","2012-06-02","2012-12-01","2012-06-21","2012-04-27")),
stringsAsFactors = FALSE
)
emp.data
emp.data<-data.frame(
emp_id=c(1:5),
emp_name=c("Souvik","Kriti","Ganesh","Pranav","Abhinav"),
)
emp.data<-data.frame(
emp_id=c(1:5),
emp_name=c("Souvik","Kriti","Ganesh","Pranav","Abhinav")
)
emp.data
class(emp.data)
as.integer(emp.data)
emp.data<-data.frame(
emp_id=c(1:5),
emp_name=c("Souvik","Kriti","Ganesh","Pranav","Abhinav")
)
emp.data
summary(data.frame())
summary(data.frame())
summary(data.frame)
summary(data.frame())
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
read.csv("sales dataset")
data<-read.csv("sales dataset.csv")
View(data)
#Get and print current working directory
print(getwd())
#import dataset
data<-read.csv("sales dataset.csv")
#import dataset
setwd("C:\Users\91825\OneDrive\Desktop\R Programming\Predictive Analysis\dataset")
#import dataset
setwd("C:\Users\91825\OneDrive\Desktop\R Programming\Predictive Analysis\dataset")
#Get and print current working directory
print(getwd())
#import dataset
setwd("C:\Users\91825\OneDrive\Desktop\R Programming\Predictive Analysis\dataset")
#Get and print current working directory
print(getwd())
#import dataset
setwd("C:\Desktop\R Programming\Predictive Analysis\dataset")
#import dataset
setwd("C:/Desktop/R Programming/Predictive Analysis/dataset")
#import dataset
setwd("C:Users/91825/OneDrive/Desktop/R Programming/Predictive Analysis/dataset")
#import dataset
setwd("C:/Users/91825/OneDrive/Desktop/R Programming/Predictive Analysis/dataset")
data<-read.csv("sales dataset.csv")
View(data)
print(is.data.frame(data))
print(ncol(data))
print(nrow(data))
str(data)
is.na(data)
str(data)
View(data)
print(is.data.frame(data))
print(ncol(data))
print(nrow(data))
str(data)
##convert itemcode datatype(char) into factor
is.factor(itemcode)
##convert itemcode datatype(char) into factor
is.factor(data$itemcode)
##convert itemcode datatype(char) into factor
factor(data$itemcode)
print(is.data.frame(data))
print(ncol(data))
print(nrow(data))
str(data)
##convert itemcode datatype(char) into factor.
factor(data$Item.code,levels = c("P1","P2","P3","P4","P5","P6"))
str(data)
##convert itemcode datatype(char) into factor.
data$Item.code<-as.factor(data$Item.code)
print(data)
str(data)
View(data)
##Get the max sale amount
sale<-max(data$Sales_Amt)
print(sale)##Get all the details those having max sales.
##Get all the details those having max sales.
df[which.max(data$Sales_Amt),]$data
##Get all the details those having max sales.
data[which.max(data$Sales_Amt),]$data
##Get all the details those having max sales.
retval<-subset(data, Sales_Amt==max(Sales_Amt))
retval
view(retval)
View(retval)
##fetch the details for finance department who have sales amount greater than 1000
info<-subset(data,data$Sales_Amt>1000 &
data$Department=="Finance")
info
View(info)
newdata<-subset(data,data$Sales_Amt>1000&
data$Department=="Finance",
select=c('Employee.Name','Employee.Country'))
View(newdata)
##fetch all the details after 1 Jan 2014.
retval<-subset(data,as.Date(data$Sales.Date,"%d-%m-%Y") >
as.Date("01-01-2014","%d-%m-%Y"))
View(retval)
##We need to import daimonds dataset(Built-in dataset)
command data(ggplot2)
?painter
??painter
??painter
##We need to import daimonds dataset(Built-in dataset)
##To get the knowledge of any particular datasets about which we don't have any idea.(e.g-diamond)
#1.?diamond
#2.data (diamond)
??diamond
??readingskills
??reading skills
??Readingskills
??Reading_skills
??Reading_Skills
??ReadingSkills
??Reading Skills
install.packages("party")
??ReadingSkills
data("readingSkills")
data("readingSkills")
View("readingSkills")
data<-data("readingSkills")
##load data
df<-data("iris")
##See the structure
head(iris)
View(df)
##load data
df<-data("iris")
View(df)
##load data
load(iris)
View(iris)
df<-data("iris")
##See the structure
head(iris)
##Generate a random number that is 90% of the total number of rows in dataset.
ran<-sample(1:nrow(iris), 0.9*nrow(iris))
str(iris)
range(iris$Sepal.Length)
range(iris$Petal.Width)
View(iris)
##the normalization function is created.
nor<-function(x){ (x-min(x))/(max(x)-min(x)) }
iris_norm<-as.data.frame(lapply(iris[,c(1,2,3,4)], nor))
summary(iris)
summary(iris_norm)
##extracting training set
iris_train <- iris_norm[ran,]
##extracting testing set
iris_test <- iris_norm[-ran,]
##extract 5th column of train dataset because it iwll be used as 'cl' argument in
##function.
iris_target_category<-iris[ran,5]
##extract 5th column if test dataset to measure the accuracy
iris_test_category<-iris[-ran,5]
##load the package class
install.packages("class")
library(class)
##run knn function
pr<-knn(iris_train,iris_test,cl=iris_target_category,k=10)
##Create confusion matrix
tab <- table(pr,iris_test_category)
##this function divides the correct predictions by total number of predictions
##that tells us how accurate the model is.
tab
accuracy<-function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
??diamond
##APPLY MACHINE LEARNING MODEL ON DIAMOND DATASET
install.packages("ggplot2")
##load data
df<-data("diamonds")
##load data
df<-data(diamond)
##load data
load(diamond)
View(diamond)
install.packages("ggplot2")
##load data
df<-data(diamond)
##load data
df<-data(diamonds)
View(diamond)
##load data
df<-data("diamonds")
##load data
df<-data("diamond")
wbcd<-read.csv("wisc_bc_data.csv")
str(wbcd)
wbcd<-wbcd[-1]
table(wbcd$diagnosis)
wbcd$diagnosis<-factor(wbcd$diagnosis, levels = c("B","M"),
labels = c("Benign","Malignant"))
round(prop.table(table(wbcd$diagnosis))*100,digits = 1)
summary(wbcd[c("radius_mean","area_mean","smoothness_mean")])
normalize<-function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n$area_mean)
wbcd_train<-wbcd_n[1:469, ]
wbcd_test<-wbcd_n[470:569, ]
wbcd_train_labels<-wbcd[1:469, 1]
wbcdd_test_labels<-wbcd[470:569, 1]
install.packages("class")
library(class)
wbcd_test_pred <- knn(train=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
install.packages("gmodels")
library(gmodels)
CrossTable(x = wbcd_test_labels,y=wbcd_test_pred,
prop.chisq=FALSE)
wbcd_train<-wbcd_n[1:469, ]
wbcd_test<-wbcd_n[470:569, ]
wbcd_train_labels<-wbcd[1:469, 1]
wbcdd_test_labels<-wbcd[470:569, 1]
wbcd_test_pred <- knn(train=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
install.packages("gmodels")
install.packages("gmodels")
library(gmodels)
CrossTable(x = wbcd_test_labels,y=wbcd_test_pred,
prop.chisq=FALSE)
wbcd_test_labels<-wbcd[470:569, 1]
wbcd_test_pred <- knn(train=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
CrossTable(x = wbcd_test_labels,y=wbcd_test_pred,
prop.chisq=FALSE)
aa<-table(wbcd_test_labels,wbcd_test_pred)
library(caret)
install.packages("caret")
confusionMatrix(aa)
library(caret)
confusionMatrix(aa)
??chickwts
cw<-load("chickwts")
cw<-load(chickwts)
install.packages("chickwts")
library(chickwts)
View(chickwts)
View(cw)
cw<-chickwts
View(cw)
str(cw)
summary(cw)
head(cw)
##Generate a random sample that is 90% of the dataset.
ran<-(1:nrow(cw) , 0.9*nrow(cw))
##Generate a random sample that is 90% of the dataset.
ran<-(1:nrow(cw), 0.9*nrow(cw))
##Generate a random sample that is 90% of the dataset.
ran <- sample(1:nrow(cw), 0.9*nrow(cw))
##Create a normalization function
nor<-function(x){ ((x-min(x))/(max(x)-min(x))) }
cw<-ChickWeight
View(cw)
str(cw)
summary(cw)
head(cw)
##Generate a random sample that is 90% of the dataset.
ran <- sample(1:nrow(cw), 0.9*nrow(cw))
##Create a normalization function
nor<-function(x){ ((x-min(x))/(max(x)-min(x))) }
wbcd<-read.csv("wisc_bc_data.csv")
str(wbcd)
install.packages("rpart")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
View(iris)
set.seed(678)
s=sample(nrow(iris),100)
iris_train=iris[s, ]
iris_test=iris[-s,]
iris_decision_tree_model = rpart(Species~., data=iris_train, method = "class")
iris_decision_tree_model
plot(iris_decision_tree_model)
text(iris_decision_tree_model)
?rpart.plot
rpart.plot(iris_decision_tree_model)
rpart.plot(iris_decision_tree_model, type=4, extra=103)
iris_predict = predict(iris_decision_tree_model, iris_test, type="class")
iris_predict_table=table(iris_test[,5], iris_predict)
iris_predict_table
(iris_performance=sum(diag(iris_predict_table))/sum(iris_predict_table))*100
data<-read.csv("TITANIC 1.CSV")
View(data)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
View(data)
data<-read.csv("TITANIC 1.csv")
View(data)
